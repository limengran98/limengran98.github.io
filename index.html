<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Mengran Li ‚Äî Technical CV</title>
  <meta name="description" content="Mengran Li ¬∑ Ph.D. Student in Control Science & Engineering, Sun Yat-sen University. AI for Science, Graph Learning, Hypergraphs, Temporal Modeling." />
  <link rel="icon" href="https://raw.githubusercontent.com/limengran98/limengran98.github.io/main/lmr.jpg" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script>tailwind.config = { darkMode: 'class' };</script>
</head>
<body class="bg-gradient-to-b from-white to-zinc-50 dark:from-zinc-950 dark:to-zinc-900 text-zinc-900 dark:text-zinc-100">

  <!-- Top Nav -->
  <nav class="sticky top-0 z-40 backdrop-blur border-b border-zinc-200/70 dark:border-zinc-800/70 bg-white/70 dark:bg-zinc-950/60">
    <div class="max-w-5xl mx-auto px-4 py-3 flex items-center justify-between">
      <a href="#about" class="font-semibold tracking-tight">Mengran Li</a>
      <div class="hidden md:flex gap-5 text-sm">
        <a href="#about">Profile</a>
        <a href="#publications">Publications</a>
        <a href="#awards">Awards</a>
        <a href="#service">Service</a>
        <a href="#contact">Contact</a>
      </div>
      <button id="darkToggle" class="border px-3 py-1.5 rounded-xl text-sm">üåô</button>
    </div>
  </nav>

  <!-- Hero -->
  <header class="max-w-5xl mx-auto px-4 pt-10 md:pt-16">
    <div class="grid md:grid-cols-[160px,1fr] gap-6 items-center">
      <img src="https://raw.githubusercontent.com/limengran98/limengran98.github.io/main/lmr.jpg" alt="Mengran Li" class="w-36 h-36 md:w-40 md:h-40 rounded-full object-cover border" />
      <div>
        <h1 class="text-3xl md:text-4xl font-bold tracking-tight">Mengran Li</h1>
        <p class="text-zinc-600 dark:text-zinc-300 mt-2">Ph.D. Student ¬∑ Control Science & Engineering ¬∑ Sun Yat-sen University</p>
        <div class="flex gap-4 mt-4 text-sm">
          <a class="underline" href="https://scholar.google.com/citations?user=MLff8bQAAAAJ&hl=en" target="_blank">Google Scholar</a>
          <a class="underline" href="https://orcid.org/0000-0001-7540-530X" target="_blank">ORCID</a>
          <a class="underline" href="https://github.com/limengran98" target="_blank">GitHub</a>
          <a class="underline" href="mailto:limr39@mail2.sysu.edu.cn">Email</a>
        </div>
      </div>
    </div>
  </header>

  <main class="max-w-5xl mx-auto px-4 pb-16">
    <!-- Profile -->
    <section id="about" class="py-6 md:py-8">
      <h2 class="text-2xl font-semibold border-b pb-3 mb-3">Profile</h2>
       <p>
        I am a Ph.D. student in Control Science and Engineering at 
        <a href="https://www.sysu.edu.cn/" target="_blank" class="text-blue-600 underline">Sun Yat-sen University</a>. 
        My research interests include AI for Science, heterogeneous graph learning, hypergraph learning, temporal modeling, traffic big data, and bioinformatics. 
        I am advised by 
        <a href="https://ise.sysu.edu.cn/teacher/ZhangRonghui" target="_blank" class="text-blue-600 underline">Prof. Ronghui Zhang (SYSU)</a> 
        and 
        <a href="https://sist.bjut.edu.cn/info/1403/2489.htm" target="_blank" class="text-blue-600 underline">Prof. Yong Zhang (BJUT)</a>. 
        As first author, I have published over 20 papers in IEEE/ACM Transactions and CCF-A conferences. 
        I also gained research experience through internships at 
        <a href="https://home.baidu.com/" target="_blank" class="text-blue-600 underline">Baidu</a>, 
        <a href="http://english.siat.cas.cn/" target="_blank" class="text-blue-600 underline">SIAT (Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology)</a>, 
        <a href="https://en.westlake.edu.cn/" target="_blank" class="text-blue-600 underline">Westlake University</a>, 
        and the 
        <a href="https://www.cair-cas.org.hk/" target="_blank" class="text-blue-600 underline">Hong Kong Centre for Artificial Intelligence and Robotics (CAIR)</a>.
       </p>
    </section>

    <!-- Education (commented out)
    <section id="education" class="py-6 md:py-8">
      <h2 class="text-2xl font-semibold border-b pb-3 mb-3">Education</h2>
      <ul class="space-y-2">
        <li><strong>2023 ‚Äì Present</strong>: Ph.D., Sun Yat-sen University</li>
        <li><strong>2020 ‚Äì 2023</strong>: M.Eng., Beijing University of Technology</li>
        <li><strong>2016 ‚Äì 2020</strong>: B.Eng., East China Jiaotong University</li>
      </ul>
    </section>
    -->

    <!-- Publications -->
    <section id="publications" class="scroll-mt-24 py-6 md:py-8">
      <h2 class="text-2xl md:text-3xl font-semibold tracking-tight border-b border-zinc-200 dark:border-zinc-800 pb-3 mb-3">Publications</h2>
      <div id="pub-list" class="space-y-10"></div>
      <div class="mt-8 text-sm">Full list on <a class="underline" href="https://scholar.google.com/citations?user=MLff8bQAAAAJ&hl=en" target="_blank">Google Scholar</a></div>
    </section>

    <!-- Awards -->
  <section id="awards" class="py-6 md:py-4">
    <h2 class="text-2xl font-semibold border-b pb-3 mb-3">Awards</h2>
    <ul class="list-disc pl-6 space-y-1">
      <li>National Scholarship for Ph.D. Students (2025)</li>
      <li>Presidential Scholarship, Sun Yat-sen University (2025)</li>
      <li>First-class Academic Scholarship, Sun Yat-sen University (2024)</li>
      <li>Outstanding Master's Thesis Award, BJUT (2023)</li>
      <li>Outstanding Graduate, BJUT (2023)</li>
      <li>Beijing Excellent Graduate (2023)</li>
      <li>Xiaomi Special Award, BJUT (Top 10 University-wide, 2022)</li>
      <li>National Scholarship for Master's Students (2022)</li>
      </ul>
    </section>

    <!-- Service -->
    <section id="service" class="py-6 md:py-8">
      <h2 class="text-2xl font-semibold border-b pb-3 mb-3">Academic Service</h2>
      <p>Reviewer for IEEE TNNLS, IEEE TCSS, IEEE TMC, IEEE TETC, ACM TIST, ACM TKDD, IEEE Communications Letters, Information Fusion, Neural Networks, Pattern Recognition, Neurocomputing, EAAI, ESWA, KBS, ACM MM, AAAI.</p>
    </section>

    <!-- Contact -->
    <section id="contact" class="py-6 md:py-8">
      <h2 class="text-2xl font-semibold border-b pb-3 mb-3">Contact</h2>
      <ul class="list-disc pl-6">
        <li><a href="mailto:limr39@mail2.sysu.edu.cn">limr39@mail2.sysu.edu.cn</a></li>
        <li><a href="mailto:limengran1998@163.com">limengran1998@163.com</a></li>
      </ul>
    </section>
  </main>

  <footer class="border-t py-10 mt-8 text-center text-sm text-zinc-500 dark:text-zinc-400">
    ¬© 2025 Mengran Li. Built with TailwindCSS.
  </footer>

  <!-- Scripts after DOM so #pub-list exists -->
  <script>
    // Dark mode
    (function(){
      const key='ml-dark';
      const root=document.documentElement;
      const saved=localStorage.getItem(key);
      if(saved==='1'||(!saved&&window.matchMedia('(prefers-color-scheme: dark)').matches)){
        root.classList.add('dark');
      }
      document.getElementById('darkToggle').addEventListener('click',()=>{
        const d=root.classList.toggle('dark');
        localStorage.setItem(key,d?'1':'0');
      });
    })();

    // ---- Publications Data

    const GRAPH_FOUNDATION_MODELS = [
      {
        title: 'A Survey of Large Language Models for Data Challenges in Graphs',
        venue: 'Expert Systems with Applications',
        year: '2025',
        paperUrl: 'https://doi.org/10.1016/j.eswa.2025.129643',
        codeUrl: 'https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges',
        authors: 'Mengran Li, Pengyu Zhang, Wenbin Xing, Yijia Zheng, Klim Zaporojets, Junzhou Chen, Ronghui Zhang, Yong Zhang, Siyuan Gong, Jia Hu, Xiaolei Ma, Zhiyuan Liu, Paul Groth, Marcel Worring',
        abstract: 'Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness, real-world graphs have missing nodes, edges, or attributes; (2) Imbalance, the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity, graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability, graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges.',
        thumbnail: ''
      },
      {
        title: 'Contextual Semantics Interaction Graph Embedding Learning for Recommender Systems',
        venue: 'ACM SIGKDD',
        year: '2025',
        paperUrl: 'https://doi.org/10.1145/3711896.3737042',
        codeUrl: 'https://github.com/Jinfeng-Xu/MDVT',
        authors: 'Jinfeng Xu, Zheyu Chen, Jinze Li, Shuo Yang, Hewei Wang, Yijie Li, Mengran Li, Puzhen Wu, Edith CH Ngai',
        abstract: 'The data sparsity problem significantly hinders the performance of recommender systems, as traditional models rely on limited historical interactions to learn user preferences and item properties. While incorporating multimodal information can explicitly represent these preferences and properties, existing works often use it only as side information, failing to fully leverage its potential. In this paper, we propose MDVT, a model-agnostic approach that constructs multimodal-driven virtual triplets to provide valuable supervision signals, effectively mitigating the data sparsity problem in multimodal recommendation systems. To ensure high-quality virtual triplets, we introduce three tailored warm-up threshold strategies: static, dynamic, and hybrid. The static warm-up threshold strategy exhaustively searches for the optimal number of warm-up epochs but is time-consuming and computationally intensive. The dynamic warm-up threshold strategy adjusts the warm-up period based on loss trends, improving efficiency but potentially missing optimal performance. The hybrid strategy combines both, using the dynamic strategy to find the approximate optimal number of warm-up epochs and then refining it with the static strategy in a narrow hyper-parameter space. Once the warm-up threshold is satisfied, the virtual triplets are used for joint model optimization by our enhanced pair-wise loss function without causing significant gradient skew. Extensive experiments on multiple real-world datasets demonstrate that integrating MDVT into advanced multimodal recommendation models effectively alleviates the data sparsity problem and improves recommendation performance, particularly in sparse data scenarios.',
        thumbnail: ''
      },
      {
        title: 'Redundancy Is Not What You Need: An Embedding Fusion Graph Auto-Encoder for Self-Supervised Graph Representation Learning',
        venue: 'IEEE TNNLS',
        year: '2025',
        paperUrl: 'https://doi.org/10.1109/TNNLS.2024.3357080',
        codeUrl: null,
        authors: 'Mengran Li, Yong Zhang, Shaofan Wang, Yongli Hu, Baocai Yin',
        abstract: 'Attribute graphs are a crucial data structure for graph communities. However, the presence of redundancy and noise in the attribute graph can impair the aggregation effect of integrating two different heterogeneous distributions of attribute and structural features, resulting in inconsistent and distorted data that ultimately compromises the accuracy and reliability of attribute graph learning. For instance, redundant or irrelevant attributes can result in overfitting, while noisy attributes can lead to underfitting. Similarly, redundant or noisy structural features can affect the accuracy of graph representations, making it challenging to distinguish between different nodes or communities. To address these issues, we propose the embedded fusion graph auto-encoder framework for self-supervised learning (SSL), which leverages multitask learning to fuse node features across different tasks to reduce redundancy. The embedding fusion graph auto-encoder (EFGAE) framework comprises two phases: pretraining (PT) and downstream task learning (DTL). During the PT phase, EFGAE uses a graph auto-encoder (GAE) based on adversarial contrastive learning to learn structural and attribute embeddings separately and then fuses these embeddings to obtain a representation of the entire graph. During the DTL phase, we introduce an adaptive graph convolutional network (AGCN), which is applied to graph neural network (GNN) classifiers to enhance recognition for downstream tasks. The experimental results demonstrate that our approach outperforms state-of-the-art (SOTA) techniques in terms of accuracy, generalization ability, and robustness.',
        thumbnail: '',
        esi: true
      },
      {
        title: 'TDG-Mamba: Advanced Spatiotemporal Embedding for Temporal Dynamic Graph Learning via Bidirectional Information Propagation',
        venue: 'IEEE TCSS',
        year: '2025',
        paperUrl: 'https://doi.org/10.1109/TCSS.2024.3509399',
        codeUrl: 'https://github.com/limengran98/TDG-Mamba',
        authors: 'Mengran Li, Junzhou Chen, Bo Li, Yong Zhang, Ronghui Zhang, Siyuan Gong, Xiaolei Ma, Zhihong Tian',
        abstract: 'Temporal dynamic graphs (TDGs), representing the dynamic evolution of entities and their relationships over time with intricate temporal features, are widely used in various real-world domains. Existing methods typically rely on mainstream techniques such as transformers and graph neural networks (GNNs) to capture the spatiotemporal information of TDGs. However, despite their advanced capabilities, these methods often struggle with significant computational complexity and limited ability to capture temporal dynamic contextual relationships. Recently, a new model architecture called mamba has emerged, noted for its capability to capture complex dependencies in sequences while significantly reducing computational complexity. Building on this, we propose a novel method, TDG-mamba, which integrates mamba for TDG learning. TDG-mamba introduces deep semantic spatiotemporal embeddings into the mamba architecture through a specially designed spatiotemporal prior tokenization module (SPTM). Furthermore, to better leverage temporal information differences and enhance the modeling of dynamic changes in graph structures, we separately design a bidirectional mamba and a directed GNN for improved spatiotemporal embedding learning. Link prediction experiments on multiple public datasets demonstrate that our method delivers superior performance, with an average improvement of 5.11\% over baseline methods across various settings.',
        thumbnail: ''
      },
      {
        title: 'Topology-Driven Attribute Recovery for Attribute Missing Graph Learning in Social Internet of Things',
        venue: 'IEEE Internet of Things Journal',
        year: '2025',
        paperUrl: 'https://doi.org/10.1109/JIOT.2025.3531985',
        codeUrl: 'https://github.com/limengran98/TDAR',
        authors: 'Mengran Li, Junzhou Chen, Chenyun Yu, Guanying Jiang, Ronghui Zhang, Yanming Shen, Houbing Herbert Song',
        abstract: 'With the advancement of information technology, the Social Internet of Things (SIoT) has fostered the integration of physical devices and social networks, deepening the study of complex interaction patterns. Text attribute graphs (TAGs) capture both topological structures and semantic attributes, enhancing the analysis of complex interactions within the SIoT. However, existing graph learning methods are typically designed for complete attributed graphs, and the common issue of missing attributes in attribute missing graphs (AMGs) increases the difficulty of analysis tasks. To address this, we propose the topology-driven attribute recovery (TDAR) framework, which leverages topological data for AMG learning. TDAR introduces an improved prefilling method for initial attribute recovery using native graph topology. Additionally, it dynamically adjusts propagation weights and incorporates homogeneity strategies within the embedding space to suit AMGs‚Äô unique topological structures, effectively reducing noise during information propagation. Extensive experiments on public datasets demonstrate that TDAR significantly outperforms state-of-the-art methods in attribute reconstruction and downstream tasks, offering a robust solution to the challenges posed by AMGs.',
        thumbnail: ''
      },
      {
        title: 'Self-Supervised Nodes-Hyperedges Embedding for Heterogeneous Information Network Learning',
        venue: 'IEEE TBD',
        year: '2024',
        paperUrl: 'https://doi.org/10.1109/TBDATA.2023.3275374',
        codeUrl: 'https://github.com/limengran98/SNHE',
        authors: 'Mengran Li, Yong Zhang, Wei Zhang, Yi Chu, Yongli Hu, Baocai Yin',
        abstract: 'The exploration of self-supervised information mining of heterogeneous datasets has gained significant traction in recent years. Heterogeneous graph neural networks (HGNNs) have emerged as a highly promising method for handling heterogeneous information networks (HINs) due to their superior performance. These networks leverage aggregation functions to convert pairwise relations-based features from raw heterogeneous graphs into embedding vectors. However, real-world HINs contain valuable higher-order relations that are often overlooked but can provide complementary information. To address this issue, we propose a novel method called Self-supervised Nodes-Hyperedges Embedding (SNHE), which leverages hypergraph structures to incorporate higher-order information into the embedding process of HINs. Our method decomposes the raw graph structure into snapshots based on various meta-paths, which are then transformed into hypergraphs to aggregate high-order information within the data and generate embedding representations. Given the complexity of HINs, we develop a dual self-supervised structure that maximizes mutual information in the enhanced graph data space, guides the overall model update, and reduces redundancy and noise. We evaluate our proposed method on various real-world datasets for node classification and clustering tasks, and compare it against state-of-the-art methods.',
        thumbnail: ''
      },
      {
        title: 'CSAT: Contrastive Sampling-Aggregating Transformer for Community Detection in Attribute-Missing Networks',
        venue: 'IEEE TCSS',
        year: '2024',
        paperUrl: 'https://doi.org/10.1109/TCSS.2023.3292145',
        codeUrl: null,
        authors: 'Mengran Li, Yong Zhang, Wei Zhang, Shiyu Zhao, Xinglin Piao, Baocai Yin',
        abstract: 'Community detection aims to identify dense subgroups of nodes within a network. However, in real-world networks, node attributes are often missing, making traditional methods less effective. In networks with missing attributes, the main challenge of community detection is to deal with the missing attribute information efficiently and use network structure information to make accurate predictions. This article proposes an innovative method called contrastive sampling-aggregating transformer (CSAT) for community detection in attribute-missing networks. CSAT incorporates the contrastive learning principle to capture hidden patterns among nodes and to aggregate information from different samples to create a more robust and accurate methodology for community detection. Specifically, CSAT utilizes a sampling and propagation strategy to obtain different samples and smooth attribute features of the network structure and leverages the Transformer architecture to model the pairwise relationships between nodes. Therefore, our method can address the attribute-missing issue by integrating the auxiliary information from both the network structure and other sources. Extensive experiments on several benchmark datasets demonstrate CSAT‚Äôs superior performance compared to the state-of-the-art methods for community detection.',
        thumbnail: ''
      },
      {
        title: 'SCAE: Structural Contrastive Auto-encoder for Incomplete Multi-view Representation Learning',
        venue: 'ACM TOMM',
        year: '2024',
        paperUrl: 'https://doi.org/10.1145/3672078',
        codeUrl: 'https://github.com/limengran98/SCAE',
        authors: 'Mengran Li, Ronghui Zhang, Yong Zhang, Xinglin Piao, Shiyu Zhao, Baocai Yin',
        abstract: 'Describing an object from multiple perspectives often leads to incomplete data representation. Consequently, learning consistent representations for missing data from multiple views has emerged as a key focus in the realm of Incomplete Multi-view Representation Learning (IMRL). In recent years, various strategies, such as subspace learning, matrix decomposition, and deep learning, have been harnessed to develop numerous IMRL methods. In this article, our primary research revolves around IMRL, with a particular emphasis on addressing two main challenges. Firstly, we delve into the effective integration of intra-view similarity and contextual structure into a unified framework. Secondly, we explore the effective facilitation of information exchange and fusion across multiple views. To tackle these issues, we propose a deep learning approach known as Structural Contrastive Auto-Encoder (SCAE) to solve the challenges of IMRL. SCAE comprises two major components: intra-view structural representation learning and inter-view contrastive representation learning. The former involves capturing intra-view similarity by minimizing the Dirichlet energy of the feature matrix, while also applying spatial dispersion regularization to capture intra-view contextual structure. The latter encourages maximizing the mutual information of inter-view representations, facilitating information exchange and fusion across views. Experimental results demonstrate the efficacy of our approach in significantly enhancing model accuracy and robustly addressing IMRL problems.',
        thumbnail: '',
        esi: true
      },
      {
        title: 'Hypergraph Transformer Neural Networks',
        venue: 'ACM TKDD',
        year: '2023',
        paperUrl: 'https://doi.org/10.1145/3565028',
        codeUrl: 'https://github.com/limengran98/HGTN',
        authors: 'Mengran Li, Yong Zhang, Xiaoyong Li, Yuchen Zhang, Baocai Yin',
        abstract: 'Graph neural networks (GNNs) have been widely used for graph structure learning and achieved excellent performance in tasks such as node classification and link prediction. Real-world graph networks imply complex and various semantic information and are often referred to as heterogeneous information networks (HINs). Previous GNNs have laboriously modeled heterogeneous graph networks with pairwise relations, in which the semantic information representation for learning is incomplete and severely hinders node embedded learning. Therefore, the conventional graph structure cannot satisfy the demand for information discovery in HINs. In this article, we propose an end-to-end hypergraph transformer neural network (HGTN) that exploits the communication abilities between different types of nodes and hyperedges to learn higher-order relations and discover semantic information. Specifically, attention mechanisms weigh the importance of semantic information hidden in original HINs to generate useful meta-paths. Meanwhile, our method develops a multi-scale attention module to aggregate node embeddings in higher-order neighborhoods. We evaluate the proposed model with node classification tasks on six datasets: DBLP, ACM, IBDM, Reuters, STUD-BJUT, and Citeseer. Experiments on a large number of benchmarks show the advantages of HGTN.',
        thumbnail: ''
      },
      {
        title: 'SHCN: Self-supervised General Hypergraph Clustering Network',
        venue: 'IEEE BigData (Conference)',
        year: '2022',
        paperUrl: 'https://doi.org/10.1109/BigData55660.2022.10020643',
        codeUrl: 'https://github.com/limengran98/SHCN',
        authors: 'Li Mengran, Piao Xinglin, Zhang Yong, Hu Yongli, Yin Baocai',
        abstract: 'Clustering is a fundamental and hot issue in the unsupervised learning area. With the rapid development of deep learning and graph neural networks (GNNs) techniques, researchers have proposed a series of effective clustering methods. However, most existing approaches adopt a conventional graph to aggregate the neighborhood information, where only the pairwise relations are considered. Moreover, the redundancy/noise in the raw data samples may result in less accurate sample relations and inferior clustering results. In this paper, we proposed a new GNNs based clustering method, which adopts the hypergraph learning approach to explore the high-order relationship for accurate relation learning. Specifically, we first construct two hypergraph representations based on the topology feature and attribute feature from data samples. Then, a self-supervised structure is integrated to learn a cross-correlation matrix from the original hypergraph to act as a higher-order neighborhood with reduced redundancy and noise. Finally the embedding representation of the clustering space is learned in the graph convolution. The proposed method has been evaluated on six public datasets for clustering tasks. Experimental results show that our proposed method outperforms the state-of-the-art ones.',
        thumbnail: ''
      }
    ];

    const GRAPH_MODELS_X = [
      {
        title: 'MM-STFlowNet: A Transportation Hub-Oriented Multi-Mode Passenger Flow Prediction Method via Spatial-Temporal Dynamic Graph Modeling',
        venue: ' IEEE Transactions on Intelligent Transportation Systems',
        year: '2025',
        paperUrl: 'https://doi.org/10.1109/TITS.2025.3588867',
        codeUrl: 'https://github.com/BMRETURN/MM-STFlowNet',
        authors: 'Ronghui Zhang, Wenbin Xing, Mengran Li, Zihan Wang, Junzhou Chen, Xiaolei Ma, Zhiyuan Liu, Zhengbing He',
        abstract: 'Accurate and refined passenger flow prediction is essential for optimizing the collaborative management of multiple collection and distribution modes in large-scale transportation hubs. Traditional methods often focus only on the overall passenger volume, neglecting the interdependence between different modes within the hub. To address this limitation, we propose MM-STFlowNet, a comprehensive multi-mode prediction framework grounded in dynamic spatial-temporal graph modeling. Initially, an integrated temporal feature processing strategy is implemented using signal decomposition and convolution techniques to address data spikes and high volatility. Subsequently, we introduce the Spatial-Temporal Dynamic Graph Convolutional Recurrent Network (STDGCRN) to capture detailed spatial-temporal dependencies across multiple traffic modes, enhanced by an adaptive channel attention mechanism. Finally, the self-attention mechanism is applied to incorporate various external factors, further enhancing prediction accuracy. Experiments on a real-world dataset from Guangzhounan Railway Station in China demonstrate that MM-STFlowNet achieves state-of-the-art performance, particularly during peak periods, providing valuable insight for transportation hub management.',
        thumbnail: ''
      },
      {
        title: 'Ms-AeDNet: A multi-scale attention-enhanced dynamic network for multi-step performance prediction of hydrogen proton exchange membrane fuel cells',
        venue: 'Process Safety and Environmental Protection',
        year: '2025',
        paperUrl: 'https://doi.org/10.1016/j.psep.2025.107674',
        codeUrl: 'https://github.com/BMRETURN/Ms-AeDNet',
        authors: 'Mengran Li, Wenbin Xing, Ronghui Zhang',
        abstract: 'The global transition to sustainable, low-carbon energy systems positions hydrogen energy as a pivotal solution for mitigating climate change and enhancing energy security. Among the most promising technologies for clean hydrogen utilization are Proton Exchange Membrane Fuel Cells (PEMFCs), known for their high efficiency and zero emissions. However, the long-term durability and performance prediction of PEMFCs remain major challenges, hindering their widespread adoption in critical sectors. Traditional methods struggle to capture the multi-scale temporal dependencies and the dynamic effects of external operating conditions. To address these challenges, we propose a Multi-scale Attention-enhanced Dynamic Network (Ms-AeDNet) that integrates global adaptive decomposition, local time enhancement, and cross-factor attentive fusion. This solution enhances the performance prediction accuracy of PEMFCs by leveraging deep learning to model degradation patterns and environmental influences simultaneously. Validated on two industrial datasets, Ms-AeDNet outperforms baseline models, reducing MAE and MSE by 27.63% and 37.48% on average. Functional contribution analysis and visualization studies further confirm its robustness across varying operating conditions, making it a reliable tool for predictive maintenance and life cycle optimization of hydrogen PEMFCs.',
        thumbnail: ''
      },
      {
        title: 'TAS-TsC: A data-driven framework for Estimating Time of Arrival using Temporal-Attribute-Spatial Tri-space Coordination of truck trajectories',
        venue: 'Applied Soft Computing',
        year: '2025',
        paperUrl: 'https://doi.org/10.1016/j.asoc.2025.113214',
        codeUrl: null,
        authors: 'Mengran Li, Junzhou Chen, Guanying Jiang, Fuliang Li, Ronghui Zhang, Siyuan Gong, Zhihan Lv',
        abstract: 'Accurately estimating the time of arrival (ETA) for trucks is crucial for optimizing transportation efficiency in logistics. GPS trajectory data provides valuable information for ETA, but challenges arise due to temporal sparsity, variable sequence lengths, and the interdependencies among multiple trucks. To address these issues, we propose the Temporal-Attribute-Spatial Tri-space Coordination (TAS-TsC) framework, which leverages three feature spaces ‚Äì temporal, attribute, and spatial ‚Äì to enhance ETA. Our framework consists of a Temporal Learning Module (TLM) that uses state space models to capture temporal dependencies, an Attribute Extraction Module (AEM) that transforms sequential features into structured attribute embeddings, and a Spatial Fusion Module (SFM) that models the interactions among multiple trajectories using graph representation learning. These modules collaboratively learn trajectory embeddings, which are then used by a Downstream Prediction Module (DPM) to estimate arrival times. We validate TAS-TsC on real truck trajectory datasets collected from Shenzhen, China, demonstrating its superior performance compared to existing methods.',
        thumbnail: ''
      },
      {
        title: 'Contextual Semantics Interaction Graph Embedding Learning for Recommender Systems',
        venue: 'IEEE TCSS',
        year: '2024',
        paperUrl: 'https://doi.org/10.1109/TCSS.2024.3394701',
        codeUrl: null,
        authors: 'Shiyu Zhao, Yong Zhang, Mengran Li, Xinglin Piao, Baocai Yin',
        abstract: 'Temporal dynamic graphs (TDGs), representing the dynamic evolution of entities and their relationships over time with intricate temporal features, are widely used in various real-world domains. Existing methods typically rely on mainstream techniques such as transformers and graph neural networks (GNNs) to capture the spatiotemporal information of TDGs. However, despite their advanced capabilities, these methods often struggle with significant computational complexity and limited ability to capture temporal dynamic contextual relationships. Recently, a new model architecture called mamba has emerged, noted for its capability to capture complex dependencies in sequences while significantly reducing computational complexity. Building on this, we propose a novel method, TDG-mamba, which integrates mamba for TDG learning. TDG-mamba introduces deep semantic spatiotemporal embeddings into the mamba architecture through a specially designed spatiotemporal prior tokenization module (SPTM). Furthermore, to better leverage temporal information differences and enhance the modeling of dynamic changes in graph structures, we separately design a bidirectional mamba and a directed GNN for improved spatiotemporal embedding learning. Link prediction experiments on multiple public datasets demonstrate that our method delivers superior performance, with an average improvement of 5.11\% over baseline methods across various settings.',
        thumbnail: ''
      },
      {
        title: 'Gene Expression Prediction from Histology Images via Hypergraph Neural Networks',
        venue: 'Briefings in Bioinformatics',
        year: '2024',
        paperUrl: 'https://academic.oup.com/bib/article/25/6/bbae500/7937248',
        codeUrl: 'https://github.com/QSong-github/HGGEP',
        authors: 'Bo Li, Yong Zhang, Qing Wang, Chengyang Zhang, Mengran Li, Guangyu Wang, Qianqian Song',
        abstract: 'Spatial transcriptomics reveals the spatial distribution of genes in complex tissues, providing crucial insights into biological processes, disease mechanisms, and drug development. The prediction of gene expression based on cost-effective histology images is a promising yet challenging field of research. Existing methods for gene prediction from histology images exhibit two major limitations. First, they ignore the intricate relationship between cell morphological information and gene expression. Second, these methods do not fully utilize the different latent stages of features extracted from the images. To address these limitations, we propose a novel hypergraph neural network model, HGGEP, to predict gene expressions from histology images. HGGEP includes a gradient enhancement module to enhance the model‚Äôs perception of cell morphological information. A lightweight backbone network extracts multiple latent stage features from the image, followed by attention mechanisms to refine the representation of features at each latent stage and capture their relations with nearby features. To explore higher-order associations among multiple latent stage features, we stack them and feed into the hypergraph to establish associations among features at different scales. Experimental results on multiple datasets from disease samples including cancers and tumor disease, demonstrate the superior performance of our HGGEP model than existing methods.',
        thumbnail: ''
      },
      {
        title: 'Inferring Student Social Links from Spatiotemporal Behavior Data via Entropy-based Analyzing Model',
        venue: 'Intelligent Data Analysis',
        year: '2023',
        paperUrl: 'https://doi.org/10.3233/IDA-216318',
        codeUrl: null,
        authors: 'Mengran Li, Yong Zhang, Xiaoyong Li, Xuanqi Lin, Baocai Yin',
        abstract: 'Social link is an important index to understand master students‚Äô mental health and social ability in educational management. Extracting hidden social strength from students‚Äô rich daily life behaviors has also become an attractive research hotspot. Devices with positioning functions record many students‚Äô spatiotemporal behavior data, which can infer students‚Äô social links. However, under the guidance of school regulations, students‚Äô daily activities have a certain regularity and periodicity. Traditional methods usually compare the co-occurrence frequency of two users to infer social association but do not consider the location-intensive and time-sensitive in campus scenes. Aiming at the campus environment, a Spatiotemporal Entropy-Based Analyzing (S-EBA) model for inferring students‚Äô social strength is proposed. The model is based on students‚Äô multi-source heterogeneous behavioral data to calculate the frequency of co-occurrence under the influence of time intervals. Then, the three features of diversity, spatiotemporal hotspot and behavior similarity are introduced to calculate social strength. Experiments show that our method is superior to the traditional methods under many evaluating criteria. The inferred social strength is used as the weight of the edge to construct a social network further to analyze its important impact on students‚Äô education management.',
        thumbnail: ''
      },
      {
        title: 'Student achievement prediction using deep neural network from multi-source campus data',
        venue: 'Complex & Intelligent Systems',
        year: '2022',
        paperUrl: 'https://doi.org/10.1007/s40747-022-00731-8',
        codeUrl: null,
        authors: 'Xiaoyong Li, Yong Zhang, Huimin Cheng, Mengran Li, Baocai Yin',
        abstract: 'Finding students at high risk of poor academic performance as early as possible plays an important role in improving education quality. To do so, most existing studies have used the traditional machine learning algorithms to predict students‚Äô achievement based on their behavior data, from which behavior features are extracted manually thanks to expert experience and knowledge. However, owing to an increase in the varieties and overall volume of behavioral data, it has become more and more challenging to identify high-quality handcrafted features. In this paper, we propose an end-to-end deep learning model that automatically extracts features from students‚Äô multi-source heterogeneous behavior data to predict academic performance. The key innovation of this model is that it uses long short-term memory networks to capture inherent time-series features for each type of behavior, and it takes two-dimensional convolutional networks to extract correlation features among different behaviors. We conducted experiments with four types of daily behavior data from students of the university in Beijing. The experimental results demonstrate that the proposed deep model method outperforms several machine learning algorithms.',
        thumbnail: ''
      },
      {
        title: 'Multi-view Hypergraph Neural Networks for Student Academic Performance Prediction',
        venue: 'Engineering Applications of Artificial Intelligence',
        year: '2022',
        paperUrl: 'https://doi.org/10.1016/j.engappai.2022.105174',
        codeUrl: null,
        authors: 'Mengran Li, Yong Zhang, Xiaoyong Li, Lijia Cai, Baocai Yin',
        abstract: 'Academic performance prediction is a fundamental and hot issue in educational data mining (EDM). Recently, researchers have proposed a series of effective machine learning (ML) based classification strategies to predict students‚Äô academic performance. However, prior arts are typically concerned about individual models but neglect the association among students, which might considerably have an effect on the integrity of the academic performance-related representations. Meanwhile, students‚Äô multi-viewing behavior contains complex relations among students. Therefore, we propose a Multi-View Hypergraph Neural Network (MVHGNN) for predicting students‚Äô academic performance. MVHGNN uses hypergraphs to construct high-order relations among students. The semantic information implied by multiple behaviors is consolidated through meta-paths. Further, a Cascade Attention Transformer (CAT) module is introduced to mine the weight of different behaviors by the self-attention mechanism. Our method is evaluated on real campus student behavioral datasets. The experimental results demonstrate that our method outperforms the state-of-the-art ones.',
        thumbnail: ''
      }

    ];

    // Render publications (with ESI badge)
    function renderCategory(categoryKey, title, list){
      const wrap = document.createElement('div');
      wrap.innerHTML = `<h3 class="text-xl font-semibold mb-3">${title}</h3>`;

      const group = document.createElement('div');
      group.className = 'space-y-4';

      list.forEach((p, i) => {
        const card = document.createElement('article');
        card.className = 'border rounded-xl p-4 bg-white/70 dark:bg-zinc-900/60';

        const head = document.createElement('div');
        head.className = 'font-medium flex items-center gap-2';

        const titleSpan = document.createElement('span');
        titleSpan.textContent = p.title;
        head.appendChild(titleSpan);

        if (p.esi) {
          const badge = document.createElement('span');
          badge.textContent = 'üî• ESI Highly Cited';
          badge.className = 'text-xs px-2 py-0.5 rounded-full bg-orange-100 text-orange-700 border border-orange-300';
          head.appendChild(badge);
        }

        const meta = document.createElement('div');
        meta.className = 'text-sm text-zinc-500 dark:text-zinc-400 mt-1';
        meta.textContent = `${p.venue}${p.year ? ', ' + p.year : ''}`;

        const actions = document.createElement('div');
        actions.className = 'flex gap-3 mt-2 items-center';

        const paperBtn = document.createElement(p.paperUrl ? 'a' : 'span');
        paperBtn.className = p.paperUrl ? 'text-blue-600' : 'text-zinc-400';
        paperBtn.innerText = 'üìÑ Paper';
        if (p.paperUrl) { paperBtn.href = p.paperUrl; paperBtn.target = '_blank'; }

        const codeBtn = document.createElement(p.codeUrl ? 'a' : 'span');
        codeBtn.className = p.codeUrl ? 'text-green-600' : 'text-zinc-400';
        codeBtn.innerText = 'üêô Code';
        if (p.codeUrl) { codeBtn.href = p.codeUrl; codeBtn.target = '_blank'; }

        const toggle = document.createElement('button');
        toggle.className = 'ml-auto text-sm underline';
        toggle.textContent = 'Details';
        const detailsId = `det-${categoryKey}-${i}`;
        toggle.setAttribute('data-toggle', detailsId);

        actions.append(paperBtn, codeBtn, toggle);

        const details = document.createElement('div');
        details.id = detailsId;
        details.className = 'hidden mt-3 text-sm text-zinc-600 dark:text-zinc-400';
        details.innerHTML = `
          ${p.authors ? `<div><strong>Authors:</strong> ${p.authors}</div>` : ''}
          ${p.abstract ? `<div class='mt-1'><strong>Abstract:</strong> ${p.abstract}</div>` : ''}
          ${p.thumbnail ? `<img src='${p.thumbnail}' alt='thumbnail' class='mt-2 rounded border'/>` : ''}
        `;

        card.append(head, meta, actions, details);
        group.append(card);
      });

      wrap.append(group);

      wrap.querySelectorAll('[data-toggle]').forEach(btn => {
        btn.addEventListener('click', () => {
          const id = btn.getAttribute('data-toggle');
          const el = wrap.querySelector('#' + CSS.escape(id));
          if (el) el.classList.toggle('hidden');
        });
      });

      return wrap;
    }

    const pubRoot = document.getElementById('pub-list');
    pubRoot.innerHTML = '';
    pubRoot.append(
      renderCategory('gfm', 'Graph Foundation Models', GRAPH_FOUNDATION_MODELS),
      renderCategory('gxx', 'Graph Models + X', GRAPH_MODELS_X)
    );
  </script>
</body>
</html>
